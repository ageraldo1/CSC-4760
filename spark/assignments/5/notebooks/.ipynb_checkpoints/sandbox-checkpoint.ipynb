{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc\n",
    "from graphframes import *\n",
    "from pyspark.sql.functions import col, asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('PageRank').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.textFile('../resources/02AdjacencyList.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_list = []\n",
    "e_list = []\n",
    "\n",
    "for node in rdd.map(lambda item: item.split(' ')).collect():\n",
    "    v_list.append((node[0], 'vertice_'+node[0]))\n",
    "    \n",
    "    for edge in range(1, len(node)):\n",
    "        e_list.append((node[0], node[edge]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = spark.createDataFrame(v_list, ['id', 'name'])\n",
    "edges = spark.createDataFrame(e_list, ['src', 'dst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "| id|     name|\n",
      "+---+---------+\n",
      "|  1|vertice_1|\n",
      "|  2|vertice_2|\n",
      "|  3|vertice_3|\n",
      "|  4|vertice_4|\n",
      "|  5|vertice_5|\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vertices.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|src|dst|\n",
      "+---+---+\n",
      "|  1|  2|\n",
      "|  2|  3|\n",
      "|  2|  4|\n",
      "|  3|  4|\n",
      "|  4|  1|\n",
      "|  4|  5|\n",
      "|  5|  3|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "edges.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PageRank DataFrame\n",
    "##### Initial Page Rank = 1\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rank = [(vertex[0], 0, 1/vertices.count(), 1/vertices.count()) for vertex in vertices.select('id').collect()]\n",
    "\n",
    "pagerank = spark.createDataFrame(l_rank, ['page', 'iteration', 'pagerank', 'perc_rank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+--------+---------+\n",
      "|page|iteration|pagerank|perc_rank|\n",
      "+----+---------+--------+---------+\n",
      "|   1|        0|     0.2|      0.2|\n",
      "|   2|        0|     0.2|      0.2|\n",
      "|   3|        0|     0.2|      0.2|\n",
      "|   4|        0|     0.2|      0.2|\n",
      "|   5|        0|     0.2|      0.2|\n",
      "+----+---------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pagerank.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_page_rank(edge, damping_factor):\n",
    "    \n",
    "    total_rank = []\n",
    "    \n",
    "    for inbound in edges.filter(f\"dst == '{edge}'\").collect():\n",
    "        last_iteration = pagerank.filter(f\"page == '{inbound['src']}'\").agg({'iteration' : 'max'}).collect()[0][0]\n",
    "        last_rank = pagerank.filter(f\"page == '{inbound['src']}'\").filter(f'iteration == {last_iteration}').select('pagerank').collect()[0][0]\n",
    "        total_outbound = edges.filter(f\"src == '{inbound['src']}'\").count()\n",
    "        \n",
    "        total_rank.append(last_rank/total_outbound)\n",
    "        \n",
    "    return (edge, last_iteration + 1, (1-damping_factor) + (damping_factor * sum(total_rank)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "damping_factor = 0.85\n",
    "rows = []\n",
    "iterations = 29\n",
    "\n",
    "for _ in range(iterations):\n",
    "    for page in vertices.select('id').collect():\n",
    "        rows.append(calc_page_rank(page[0], damping_factor))\n",
    "  \n",
    "    newRows = spark.createDataFrame(rows)\n",
    "    sum_pr = newRows.select(newRows.columns[-1]).agg({f'{newRows.columns[-1]}' : 'sum'}).collect()[0][0]    \n",
    "    newRows = newRows.withColumn(\"perc_rank\", (newRows[f'{newRows.columns[-1]}']/sum_pr))\n",
    "    \n",
    "    pagerank = pagerank.union(newRows)\n",
    "    rows.clear() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------------+-------------------+\n",
      "|page|iteration|          pagerank|          perc_rank|\n",
      "+----+---------+------------------+-------------------+\n",
      "|   1|       29|0.7723196821160265|0.15558130445306423|\n",
      "|   2|       29|0.8056407707925519|0.16229373010028633|\n",
      "|   3|       29|1.1476149730879313|0.23118332817014126|\n",
      "|   4|       29|1.4661954349708077| 0.2953603328234441|\n",
      "|   5|       29|0.7723196821160265|0.15558130445306423|\n",
      "+----+---------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "last_iteration = pagerank.agg({'iteration' : 'max'}).collect()[0][0]\n",
    "\n",
    "pagerank.filter(f\"iteration == {last_iteration}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"x4\", df.pagerank/sum_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------------+-------------------+\n",
      "|page|iteration|          pagerank|                 x4|\n",
      "+----+---------+------------------+-------------------+\n",
      "|   1|       30|0.7731330598625933| 0.1555763445194499|\n",
      "|   2|       30|0.8064717297986226|0.16228503241427328|\n",
      "|   3|       30|1.1488690573854572|0.23118510584879393|\n",
      "|   4|       30|1.4678700547115762| 0.2953771726980331|\n",
      "|   5|       30|0.7731330598625933| 0.1555763445194499|\n",
      "+----+---------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(df.columns[-1]).agg({f'{df.columns[-1]}' : 'sum'}).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"x5\", df['pagerank']/sum_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------------------+-------------------+-------------------+\n",
      "|page|iteration|          pagerank|                 x4|                 x5|\n",
      "+----+---------+------------------+-------------------+-------------------+\n",
      "|   1|       30|0.7731330598625933| 0.1555763445194499|0.48320816241412073|\n",
      "|   2|       30|0.8064717297986226|0.16228503241427328|  0.504044831124139|\n",
      "|   3|       30|1.1488690573854572|0.23118510584879393| 0.7180431608659106|\n",
      "|   4|       30|1.4678700547115762| 0.2953771726980331| 0.9174187841947349|\n",
      "|   5|       30|0.7731330598625933| 0.1555763445194499|0.48320816241412073|\n",
      "+----+---------+------------------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------------------+---------+\n",
      "| _1| _2|                 _3|perc_rank|\n",
      "+---+---+-------------------+---------+\n",
      "|  1|  1|0.23500000000000004| 0.146875|\n",
      "|  2|  1|0.32000000000000006|      0.2|\n",
      "|  3|  1|              0.405| 0.253125|\n",
      "|  4|  1|              0.405| 0.253125|\n",
      "|  5|  1|0.23500000000000004| 0.146875|\n",
      "+---+---+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#    newRows = spark.createDataFrame(rows)\n",
    "#    tempRows = newRows\n",
    "#    sum_pr = newRows.select(newRows.columns[-1]).agg({f'{newRows.columns[-1]}' : 'sum'}).collect()[0][0]    \n",
    "#    newRows = newRows.withColumn(\"perc_rank\", (newRows[f'{newRows.columns[-2]}']/sum_pr))\n",
    "\n",
    "\n",
    "sum_pr = tempRows.select(tempRows.columns[-1]).agg({f'{tempRows.columns[-1]}' : 'sum'}).collect()[0][0]\n",
    "col = tempRows.columns[-1]\n",
    "#print(sum_pr)\n",
    "\n",
    "#print(col)\n",
    "#tempRows.withColumn(\"perc_rank\", (tempRows[f'{col}']/sum_pr)).show()\n",
    "tempRows.withColumn(\"perc_rank\", (tempRows[f'{tempRows.columns[-1]}']/sum_pr)).show()\n",
    "\n",
    "#tempRows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
